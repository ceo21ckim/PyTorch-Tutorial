{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.optim as optim \n",
    "from torch.utils.data import DataLoader \n",
    "\n",
    "import torchvision.transforms as transforms \n",
    "import torchvision.datasets as dsets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "train_dataset = dsets.MNIST(root='./data', \n",
    "                            train=True, \n",
    "                            transform=transforms.ToTensor(), \n",
    "                            download=True)\n",
    "\n",
    "test_dataset = dsets.MNIST(root='./data', \n",
    "                            train=False, \n",
    "                            transform=transforms.ToTensor(), \n",
    "                            download=True)\n",
    "\n",
    "batch_size=100\n",
    "n_iter = 3000\n",
    "n_epochs = int(n_iter / (len(train_dataset) / batch_size))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(FFNN, self).__init__()\n",
    "        self.input_dim = input_dim \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim \n",
    "        \n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim) \n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim) \n",
    "        self.relu = nn.ReLU() \n",
    "        \n",
    "        self._init_weight()\n",
    "    \n",
    "    def forward(self, images):\n",
    "        images = images.view(-1, self.input_dim)\n",
    "        \n",
    "        out = self.fc1(images) \n",
    "        out = self.relu(out) \n",
    "        \n",
    "        out = self.fc2(out) \n",
    "        return out \n",
    "\n",
    "    def _init_weight(self):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                print(f'initializing... {module}')\n",
    "                nn.init.kaiming_normal_(module.weight) \n",
    "                nn.init.zeros_(module.bias)               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing... Linear(in_features=784, out_features=100, bias=True)\n",
      "initializing... Linear(in_features=100, out_features=10, bias=True)\n"
     ]
    }
   ],
   "source": [
    "input_dim = 28 * 28\n",
    "hidden_dim = 100 \n",
    "output_dim = 10 \n",
    "learning_rate = 1e-1\n",
    "\n",
    "model = FFNN(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 500, Loss: 0.1771, Accuracy: 93.87%\n",
      "Iteration: 1000, Loss: 0.2288, Accuracy: 94.66%\n",
      "Iteration: 1500, Loss: 0.1610, Accuracy: 95.23%\n",
      "Iteration: 2000, Loss: 0.0962, Accuracy: 95.82%\n",
      "Iteration: 2500, Loss: 0.1703, Accuracy: 96.17%\n",
      "Iteration: 3000, Loss: 0.0795, Accuracy: 96.50%\n"
     ]
    }
   ],
   "source": [
    "iter = 0 \n",
    "for epoch in range(1, n_epochs+1):\n",
    "    \n",
    "    model.train()\n",
    "    for (images, labels) in train_loader:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        pred_y = model(images)\n",
    "        loss = criterion(pred_y, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        iter += 1 \n",
    "        \n",
    "        if iter % 500 == 0 :\n",
    "            correct, total = 0, 0\n",
    "            \n",
    "            model.eval()\n",
    "            for (images, labels) in test_loader:\n",
    "                \n",
    "                pred_y = model(images)\n",
    "                loss = criterion(pred_y, labels)\n",
    "                pred_y = torch.argmax(pred_y, dim=1)\n",
    "                \n",
    "                total += len(labels)\n",
    "                correct += (pred_y == labels).sum()\n",
    "            \n",
    "            accuracy = 100 * correct / total \n",
    "            \n",
    "            print(f'Iteration: {iter}, Loss: {loss.item():.4f}, Accuracy: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Models parameters: $\\theta \\in \\mathcal{R}^d$\n",
    "- Loss function: $J(\\theta)$\n",
    "- Gradient w.r.t. parameters: $\\nabla J(\\theta)$\n",
    "- Learning rate: $\\eta$\n",
    "- Batch Gradient Descent: $\\theta = \\theta - \\eta \\cdot \\nabla J(\\theta)$\n",
    "- Stochastic Gradient Descent: $\\theta = \\theta - \\eta \\cdot \\nabla J(\\theta, x^i, y^i)$\n",
    "- Mini-Bacth Gradient Descent: $\\theta = \\theta - \\eta \\cdot \\nabla J(\\theta, x^{i:i+n}, y^{i:i+n})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD Momentum\n",
    "\n",
    "- $v_t = \\gamma v_{t-1} + \\eta \\cdot \\nabla J(\\theta, x^{i:i+n}, y^{i:i+n})$\n",
    "- $\\theta = \\theta - v_t$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing... Linear(in_features=784, out_features=100, bias=True)\n",
      "initializing... Linear(in_features=100, out_features=10, bias=True)\n",
      "Iteration: 500, Loss: 0.1375, Accuracy: 95.22%\n",
      "Iteration: 1000, Loss: 0.0629, Accuracy: 96.55%\n",
      "Iteration: 1500, Loss: 0.0233, Accuracy: 97.36%\n",
      "Iteration: 2000, Loss: 0.1141, Accuracy: 97.00%\n",
      "Iteration: 2500, Loss: 0.0622, Accuracy: 97.42%\n",
      "Iteration: 3000, Loss: 0.1135, Accuracy: 97.39%\n"
     ]
    }
   ],
   "source": [
    "class FFNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(FFNN, self).__init__()\n",
    "        self.input_dim = input_dim \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim \n",
    "        \n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim) \n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim) \n",
    "        self.relu = nn.ReLU() \n",
    "        \n",
    "        self._init_weight()\n",
    "    \n",
    "    def forward(self, images):\n",
    "        images = images.view(-1, self.input_dim)\n",
    "        \n",
    "        out = self.fc1(images) \n",
    "        out = self.relu(out) \n",
    "        \n",
    "        out = self.fc2(out) \n",
    "        return out \n",
    "\n",
    "    def _init_weight(self):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                print(f'initializing... {module}')\n",
    "                nn.init.kaiming_normal_(module.weight) \n",
    "                nn.init.zeros_(module.bias)               \n",
    "\n",
    "input_dim = 28 * 28\n",
    "hidden_dim = 100 \n",
    "output_dim = 10 \n",
    "learning_rate = 1e-1\n",
    "\n",
    "model = FFNN(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "\n",
    "iter = 0 \n",
    "for epoch in range(1, n_epochs+1):\n",
    "    \n",
    "    model.train()\n",
    "    for (images, labels) in train_loader:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        pred_y = model(images)\n",
    "        loss = criterion(pred_y, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        iter += 1 \n",
    "        \n",
    "        if iter % 500 == 0 :\n",
    "            correct, total = 0, 0\n",
    "            \n",
    "            model.eval()\n",
    "            for (images, labels) in test_loader:\n",
    "                \n",
    "                pred_y = model(images)\n",
    "                loss = criterion(pred_y, labels)\n",
    "                pred_y = torch.argmax(pred_y, dim=1)\n",
    "                \n",
    "                total += len(labels)\n",
    "                correct += (pred_y == labels).sum()\n",
    "            \n",
    "            accuracy = 100 * correct / total \n",
    "            \n",
    "            print(f'Iteration: {iter}, Loss: {loss.item():.4f}, Accuracy: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD nesterov momentum\n",
    "\n",
    "- $v_t = \\gamma v_{t-1} + \\eta \\cdot \\nabla J(\\theta - \\gamma v_{t-1}, x^{i:i+n}, y^{i:i+n})$ \n",
    "- $\\theta = \\theta - v_t $\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing... Linear(in_features=784, out_features=100, bias=True)\n",
      "initializing... Linear(in_features=100, out_features=10, bias=True)\n",
      "Iteration: 500, Loss: 0.1189, Accuracy: 96.16%\n",
      "Iteration: 1000, Loss: 0.1993, Accuracy: 96.66%\n",
      "Iteration: 1500, Loss: 0.1848, Accuracy: 96.92%\n",
      "Iteration: 2000, Loss: 0.0597, Accuracy: 97.19%\n",
      "Iteration: 2500, Loss: 0.0826, Accuracy: 97.71%\n",
      "Iteration: 3000, Loss: 0.1586, Accuracy: 97.39%\n"
     ]
    }
   ],
   "source": [
    "class FFNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(FFNN, self).__init__()\n",
    "        self.input_dim = input_dim \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim \n",
    "        \n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim) \n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim) \n",
    "        self.relu = nn.ReLU() \n",
    "        \n",
    "        self._init_weight()\n",
    "    \n",
    "    def forward(self, images):\n",
    "        images = images.view(-1, self.input_dim)\n",
    "        \n",
    "        out = self.fc1(images) \n",
    "        out = self.relu(out) \n",
    "        \n",
    "        out = self.fc2(out) \n",
    "        return out \n",
    "\n",
    "    def _init_weight(self):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                print(f'initializing... {module}')\n",
    "                nn.init.kaiming_normal_(module.weight) \n",
    "                nn.init.zeros_(module.bias)               \n",
    "\n",
    "input_dim = 28 * 28\n",
    "hidden_dim = 100 \n",
    "output_dim = 10 \n",
    "learning_rate = 1e-1\n",
    "\n",
    "model = FFNN(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, nesterov=True)\n",
    "\n",
    "iter = 0 \n",
    "for epoch in range(1, n_epochs+1):\n",
    "    \n",
    "    model.train()\n",
    "    for (images, labels) in train_loader:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        pred_y = model(images)\n",
    "        loss = criterion(pred_y, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        iter += 1 \n",
    "        \n",
    "        if iter % 500 == 0 :\n",
    "            correct, total = 0, 0\n",
    "            \n",
    "            model.eval()\n",
    "            for (images, labels) in test_loader:\n",
    "                \n",
    "                pred_y = model(images)\n",
    "                loss = criterion(pred_y, labels)\n",
    "                pred_y = torch.argmax(pred_y, dim=1)\n",
    "                \n",
    "                total += len(labels)\n",
    "                correct += (pred_y == labels).sum()\n",
    "            \n",
    "            accuracy = 100 * correct / total \n",
    "            \n",
    "            print(f'Iteration: {iter}, Loss: {loss.item():.4f}, Accuracy: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adam \n",
    "\n",
    "- $m_t = \\beta_1 m_{t-1} + (1-\\beta_1)g_t$\n",
    "- $v_t = \\beta_2 v_{t-1} + (1-\\beta_2)g^2_t$\n",
    "- $\\hat{m}_t = \\frac{m_t}{1-\\beta_2}$\n",
    "- $\\hat{v}_t = \\frac{v_t}{1-\\beta_2}$\n",
    "- $\\theta_{t+1} = \\theta_t - \\frac{\\eta}{\\sqrt{\\hat{v}_t}+\\epsilon}\\cdot \\hat{m}_t$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing... Linear(in_features=784, out_features=100, bias=True)\n",
      "initializing... Linear(in_features=100, out_features=10, bias=True)\n",
      "Iteration: 500, Loss: 0.3647, Accuracy: 94.01%\n",
      "Iteration: 1000, Loss: 0.1764, Accuracy: 95.37%\n",
      "Iteration: 1500, Loss: 0.0639, Accuracy: 96.45%\n",
      "Iteration: 2000, Loss: 0.0908, Accuracy: 96.85%\n",
      "Iteration: 2500, Loss: 0.1346, Accuracy: 96.97%\n",
      "Iteration: 3000, Loss: 0.1018, Accuracy: 97.14%\n"
     ]
    }
   ],
   "source": [
    "class FFNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(FFNN, self).__init__()\n",
    "        self.input_dim = input_dim \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim \n",
    "        \n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim) \n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim) \n",
    "        self.relu = nn.ReLU() \n",
    "        \n",
    "        self._init_weight()\n",
    "    \n",
    "    def forward(self, images):\n",
    "        images = images.view(-1, self.input_dim)\n",
    "        \n",
    "        out = self.fc1(images) \n",
    "        out = self.relu(out) \n",
    "        \n",
    "        out = self.fc2(out) \n",
    "        return out \n",
    "\n",
    "    def _init_weight(self):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                print(f'initializing... {module}')\n",
    "                nn.init.kaiming_normal_(module.weight) \n",
    "                nn.init.zeros_(module.bias)               \n",
    "\n",
    "input_dim = 28 * 28\n",
    "hidden_dim = 100 \n",
    "output_dim = 10 \n",
    "\n",
    "model = FFNN(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters()) # learning_rate=0.01\n",
    "\n",
    "iter = 0 \n",
    "for epoch in range(1, n_epochs+1):\n",
    "    \n",
    "    model.train()\n",
    "    for (images, labels) in train_loader:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        pred_y = model(images)\n",
    "        loss = criterion(pred_y, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        iter += 1 \n",
    "        \n",
    "        if iter % 500 == 0 :\n",
    "            correct, total = 0, 0\n",
    "            \n",
    "            model.eval()\n",
    "            for (images, labels) in test_loader:\n",
    "                \n",
    "                pred_y = model(images)\n",
    "                loss = criterion(pred_y, labels)\n",
    "                pred_y = torch.argmax(pred_y, dim=1)\n",
    "                \n",
    "                total += len(labels)\n",
    "                correct += (pred_y == labels).sum()\n",
    "            \n",
    "            accuracy = 100 * correct / total \n",
    "            \n",
    "            print(f'Iteration: {iter}, Loss: {loss.item():.4f}, Accuracy: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adagrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing... Linear(in_features=784, out_features=100, bias=True)\n",
      "initializing... Linear(in_features=100, out_features=10, bias=True)\n",
      "Iteration: 500, Loss: 0.1597, Accuracy: 93.70%\n",
      "Iteration: 1000, Loss: 0.1298, Accuracy: 94.70%\n",
      "Iteration: 1500, Loss: 0.1998, Accuracy: 95.34%\n",
      "Iteration: 2000, Loss: 0.1116, Accuracy: 95.66%\n",
      "Iteration: 2500, Loss: 0.1493, Accuracy: 95.86%\n",
      "Iteration: 3000, Loss: 0.1239, Accuracy: 96.20%\n"
     ]
    }
   ],
   "source": [
    "class FFNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(FFNN, self).__init__()\n",
    "        self.input_dim = input_dim \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim \n",
    "        \n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim) \n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim) \n",
    "        self.relu = nn.ReLU() \n",
    "        \n",
    "        self._init_weight()\n",
    "    \n",
    "    def forward(self, images):\n",
    "        images = images.view(-1, self.input_dim)\n",
    "        \n",
    "        out = self.fc1(images) \n",
    "        out = self.relu(out) \n",
    "        \n",
    "        out = self.fc2(out) \n",
    "        return out \n",
    "\n",
    "    def _init_weight(self):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                print(f'initializing... {module}')\n",
    "                nn.init.kaiming_normal_(module.weight) \n",
    "                nn.init.zeros_(module.bias)               \n",
    "\n",
    "input_dim = 28 * 28\n",
    "hidden_dim = 100 \n",
    "output_dim = 10 \n",
    "\n",
    "model = FFNN(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adagrad(model.parameters()) # learning_rate = 0.01\n",
    "\n",
    "iter = 0 \n",
    "for epoch in range(1, n_epochs+1):\n",
    "    \n",
    "    model.train()\n",
    "    for (images, labels) in train_loader:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        pred_y = model(images)\n",
    "        loss = criterion(pred_y, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        iter += 1 \n",
    "        \n",
    "        if iter % 500 == 0 :\n",
    "            correct, total = 0, 0\n",
    "            \n",
    "            model.eval()\n",
    "            for (images, labels) in test_loader:\n",
    "                \n",
    "                pred_y = model(images)\n",
    "                loss = criterion(pred_y, labels)\n",
    "                pred_y = torch.argmax(pred_y, dim=1)\n",
    "                \n",
    "                total += len(labels)\n",
    "                correct += (pred_y == labels).sum()\n",
    "            \n",
    "            accuracy = 100 * correct / total \n",
    "            \n",
    "            print(f'Iteration: {iter}, Loss: {loss.item():.4f}, Accuracy: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adadelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing... Linear(in_features=784, out_features=100, bias=True)\n",
      "initializing... Linear(in_features=100, out_features=10, bias=True)\n",
      "Iteration: 500, Loss: 0.0812, Accuracy: 94.97%\n",
      "Iteration: 1000, Loss: 0.1112, Accuracy: 96.39%\n",
      "Iteration: 1500, Loss: 0.0638, Accuracy: 97.08%\n",
      "Iteration: 2000, Loss: 0.0848, Accuracy: 97.07%\n",
      "Iteration: 2500, Loss: 0.1084, Accuracy: 97.28%\n",
      "Iteration: 3000, Loss: 0.1699, Accuracy: 96.80%\n"
     ]
    }
   ],
   "source": [
    "class FFNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(FFNN, self).__init__()\n",
    "        self.input_dim = input_dim \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim \n",
    "        \n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim) \n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim) \n",
    "        self.relu = nn.ReLU() \n",
    "        \n",
    "        self._init_weight()\n",
    "    \n",
    "    def forward(self, images):\n",
    "        images = images.view(-1, self.input_dim)\n",
    "        \n",
    "        out = self.fc1(images) \n",
    "        out = self.relu(out) \n",
    "        \n",
    "        out = self.fc2(out) \n",
    "        return out \n",
    "\n",
    "    def _init_weight(self):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                print(f'initializing... {module}')\n",
    "                nn.init.kaiming_normal_(module.weight) \n",
    "                nn.init.zeros_(module.bias)               \n",
    "\n",
    "input_dim = 28 * 28\n",
    "hidden_dim = 100 \n",
    "output_dim = 10 \n",
    "\n",
    "model = FFNN(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adadelta(model.parameters()) # learning_rate = 0.01\n",
    "\n",
    "iter = 0 \n",
    "for epoch in range(1, n_epochs+1):\n",
    "    \n",
    "    model.train()\n",
    "    for (images, labels) in train_loader:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        pred_y = model(images)\n",
    "        loss = criterion(pred_y, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        iter += 1 \n",
    "        \n",
    "        if iter % 500 == 0 :\n",
    "            correct, total = 0, 0\n",
    "            \n",
    "            model.eval()\n",
    "            for (images, labels) in test_loader:\n",
    "                \n",
    "                pred_y = model(images)\n",
    "                loss = criterion(pred_y, labels)\n",
    "                pred_y = torch.argmax(pred_y, dim=1)\n",
    "                \n",
    "                total += len(labels)\n",
    "                correct += (pred_y == labels).sum()\n",
    "            \n",
    "            accuracy = 100 * correct / total \n",
    "            \n",
    "            print(f'Iteration: {iter}, Loss: {loss.item():.4f}, Accuracy: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adamax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing... Linear(in_features=784, out_features=100, bias=True)\n",
      "initializing... Linear(in_features=100, out_features=10, bias=True)\n",
      "Iteration: 500, Loss: 0.1205, Accuracy: 94.64%\n",
      "Iteration: 1000, Loss: 0.0881, Accuracy: 95.98%\n",
      "Iteration: 1500, Loss: 0.1541, Accuracy: 96.85%\n",
      "Iteration: 2000, Loss: 0.0592, Accuracy: 97.47%\n",
      "Iteration: 2500, Loss: 0.0624, Accuracy: 97.58%\n",
      "Iteration: 3000, Loss: 0.0362, Accuracy: 97.50%\n"
     ]
    }
   ],
   "source": [
    "class FFNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(FFNN, self).__init__()\n",
    "        self.input_dim = input_dim \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim \n",
    "        \n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim) \n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim) \n",
    "        self.relu = nn.ReLU() \n",
    "        \n",
    "        self._init_weight()\n",
    "    \n",
    "    def forward(self, images):\n",
    "        images = images.view(-1, self.input_dim)\n",
    "        \n",
    "        out = self.fc1(images) \n",
    "        out = self.relu(out) \n",
    "        \n",
    "        out = self.fc2(out) \n",
    "        return out \n",
    "\n",
    "    def _init_weight(self):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                print(f'initializing... {module}')\n",
    "                nn.init.kaiming_normal_(module.weight) \n",
    "                nn.init.zeros_(module.bias)               \n",
    "\n",
    "input_dim = 28 * 28\n",
    "hidden_dim = 100 \n",
    "output_dim = 10 \n",
    "learning_rate = 1e-1\n",
    "\n",
    "model = FFNN(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adadelta(model.parameters()) # learning_rate = 0.01\n",
    "\n",
    "iter = 0 \n",
    "for epoch in range(1, n_epochs+1):\n",
    "    \n",
    "    model.train()\n",
    "    for (images, labels) in train_loader:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        pred_y = model(images)\n",
    "        loss = criterion(pred_y, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        iter += 1 \n",
    "        \n",
    "        if iter % 500 == 0 :\n",
    "            correct, total = 0, 0\n",
    "            \n",
    "            model.eval()\n",
    "            for (images, labels) in test_loader:\n",
    "                \n",
    "                pred_y = model(images)\n",
    "                loss = criterion(pred_y, labels)\n",
    "                pred_y = torch.argmax(pred_y, dim=1)\n",
    "                \n",
    "                total += len(labels)\n",
    "                correct += (pred_y == labels).sum()\n",
    "            \n",
    "            accuracy = 100 * correct / total \n",
    "            \n",
    "            print(f'Iteration: {iter}, Loss: {loss.item():.4f}, Accuracy: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RMSProp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing... Linear(in_features=784, out_features=100, bias=True)\n",
      "initializing... Linear(in_features=100, out_features=10, bias=True)\n",
      "Iteration: 500, Loss: 0.1782, Accuracy: 95.18%\n",
      "Iteration: 1000, Loss: 0.2938, Accuracy: 96.60%\n",
      "Iteration: 1500, Loss: 0.0240, Accuracy: 96.46%\n",
      "Iteration: 2000, Loss: 0.0837, Accuracy: 95.75%\n",
      "Iteration: 2500, Loss: 0.0755, Accuracy: 96.71%\n",
      "Iteration: 3000, Loss: 0.2874, Accuracy: 96.60%\n"
     ]
    }
   ],
   "source": [
    "class FFNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(FFNN, self).__init__()\n",
    "        self.input_dim = input_dim \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim \n",
    "        \n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim) \n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim) \n",
    "        self.relu = nn.ReLU() \n",
    "        \n",
    "        self._init_weight()\n",
    "    \n",
    "    def forward(self, images):\n",
    "        images = images.view(-1, self.input_dim)\n",
    "        \n",
    "        out = self.fc1(images) \n",
    "        out = self.relu(out) \n",
    "        \n",
    "        out = self.fc2(out) \n",
    "        return out \n",
    "\n",
    "    def _init_weight(self):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                print(f'initializing... {module}')\n",
    "                nn.init.kaiming_normal_(module.weight) \n",
    "                nn.init.zeros_(module.bias)               \n",
    "\n",
    "input_dim = 28 * 28\n",
    "hidden_dim = 100 \n",
    "output_dim = 10 \n",
    "\n",
    "model = FFNN(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.RMSprop(model.parameters()) # learning_rate = 0.01\n",
    "\n",
    "iter = 0 \n",
    "for epoch in range(1, n_epochs+1):\n",
    "    \n",
    "    model.train()\n",
    "    for (images, labels) in train_loader:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        pred_y = model(images)\n",
    "        loss = criterion(pred_y, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        iter += 1 \n",
    "        \n",
    "        if iter % 500 == 0 :\n",
    "            correct, total = 0, 0\n",
    "            \n",
    "            model.eval()\n",
    "            for (images, labels) in test_loader:\n",
    "                \n",
    "                pred_y = model(images)\n",
    "                loss = criterion(pred_y, labels)\n",
    "                pred_y = torch.argmax(pred_y, dim=1)\n",
    "                \n",
    "                total += len(labels)\n",
    "                correct += (pred_y == labels).sum()\n",
    "            \n",
    "            accuracy = 100 * correct / total \n",
    "            \n",
    "            print(f'Iteration: {iter}, Loss: {loss.item():.4f}, Accuracy: {accuracy:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "116e0bc72a1820dee7c1d3f3e708778f7416cc41eb6b2ea33b8e8b62fc39e31e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
