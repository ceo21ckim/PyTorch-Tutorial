{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os, time\n",
    "import numpy as np \n",
    "from tqdm import tqdm \n",
    "from string import punctuation\n",
    "from collections import Counter \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch \n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1ea84cdd1b0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEED = 1004\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12500/12500 [00:32<00:00, 387.32it/s]\n",
      "100%|██████████| 12500/12500 [00:32<00:00, 383.54it/s]\n"
     ]
    }
   ],
   "source": [
    "# review_list, label_list = [], []\n",
    "# for label in ['pos', 'neg']:\n",
    "#     for fname in tqdm(os.listdir(f'./aclImdb/train/{label}/')):\n",
    "#         if 'txt' not in fname:\n",
    "#             continue \n",
    "        \n",
    "#         with open(\n",
    "#             os.path.join(f'./aclImdb/train/{label}/', fname), encoding='utf-8'\n",
    "#         ) as f:\n",
    "#             review_list += [f.read()]\n",
    "#             label_list += [label]\n",
    "\n",
    "\n",
    "# import random \n",
    "# sample = random.sample(range(25000), 10000)\n",
    "\n",
    "\n",
    "# review_lists = list(np.array(review_list)[sample])\n",
    "# label_lists = list(np.array(label_list)[sample])\n",
    "\n",
    "\n",
    "# with open(f'./data.txt', 'w', encoding='utf-8-sig') as f:\n",
    "#     for review, label in zip(review_lists, label_lists):\n",
    "#         f.write(f'{review}\\t{label}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = os.path.join(os.getcwd(), 'reviews.txt')\n",
    "review_list, label_list = [], []\n",
    "with open(PATH, 'r', encoding='utf-8-sig') as datasets:\n",
    "    for d_set in datasets:\n",
    "        d_set = d_set.strip()\n",
    "        review, label = d_set[:-3], d_set[-3:] # pos, neg\n",
    "        review_list.append(review)\n",
    "        label_list.append(label)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:00<00:00, 33429.75it/s]\n"
     ]
    }
   ],
   "source": [
    "review_list = [review.lower() for review in review_list]\n",
    "review_list = [\n",
    "    ''.join([letter for letter in review if letter not in punctuation]) for review in tqdm(review_list)\n",
    "] # remove punctuation\n",
    "\n",
    "reviews_blob = ' '.join(review_list)\n",
    "\n",
    "review_words = reviews_blob.split()\n",
    "\n",
    "count_words = Counter(review_words)\n",
    "\n",
    "total_review_words = len(review_words)\n",
    "sorted_review_words = count_words.most_common(total_review_words)\n",
    "\n",
    "# the most of words are stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build vocaburary\n",
    "vocab_to_token = {\n",
    "    word:idx + 1 for idx, (word, count) in enumerate(sorted_review_words)\n",
    "}\n",
    "\n",
    "# word to token \n",
    "reviews_tokenized = []\n",
    "\n",
    "for review in review_list:\n",
    "    word_to_token = [vocab_to_token[word] for word in review.split()]\n",
    "    reviews_tokenized.append(word_to_token) # the -> 1, and -> 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'neg',\n",
       " 'pos',\n",
       " ...]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_label_list = [1 if label == 'pos' else 0 for label in label_list]\n",
    "\n",
    "reviews_len = [len(review) for review in reviews_tokenized]\n",
    "\n",
    "reviews_tokenized = [\n",
    "    reviews_tokenized[i] for i, l in enumerate(reviews_len) if l > 0 \n",
    "]\n",
    "\n",
    "encoded_label_list = np.array(\n",
    "    [encoded_label_list[i] for i, l in enumerate(reviews_len) if l > 0], dtype='float32'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def pad_sequence(reviews_tokenized, sequence_length):\n",
    "    padded_reviews = np.zeros((len(reviews_tokenized), sequence_length), dtype=int)\n",
    "    \n",
    "    for idx, review in enumerate(reviews_tokenized):\n",
    "        review_len = len(review)\n",
    "        \n",
    "        if review_len <= sequence_length:\n",
    "            zeroes = list(np.zeros(sequence_length - review_len))\n",
    "            new_sequence = zeroes + review # zero padding \n",
    "            \n",
    "        elif review_len > sequence_length:\n",
    "            new_sequence = review[:sequence_length]\n",
    "            \n",
    "        padded_reviews[idx, :] = np.array(new_sequence)\n",
    "    \n",
    "    return padded_reviews\n",
    "\n",
    "sequence_length = 512 \n",
    "padded_reviews = pad_sequence(\n",
    "    reviews_tokenized = reviews_tokenized, sequence_length=sequence_length\n",
    ")\n",
    "\n",
    "plt.hist(reviews_len);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_valid_ratio = 0.75\n",
    "train_x = padded_reviews[:int(train_valid_ratio*len(padded_reviews))]\n",
    "train_y = encoded_label_list[:int(train_valid_ratio*len(padded_reviews))]\n",
    "\n",
    "valid_x = padded_reviews[int(train_valid_ratio*len(padded_reviews)):]\n",
    "valid_y = encoded_label_list[int(train_valid_ratio*len(padded_reviews)):]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        super(RNNDataset, self).__init__()\n",
    "        \n",
    "        self.X = X \n",
    "        self.y = y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.X[idx]\n",
    "        y = self.y[idx]\n",
    "        \n",
    "        return (\n",
    "            torch.tensor(x), \n",
    "            torch.tensor(y)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = RNNDataset(train_x, train_y)\n",
    "valid_dataset = RNNDataset(valid_x, valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1250.0"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_y.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512 \n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hidden_dim, out_dim):\n",
    "        super(RNN, self).__init__()\n",
    "        self.embedding_layer = nn.Embedding(input_dim, emb_dim)\n",
    "        self.rnn_layer = nn.RNN(emb_dim, hidden_dim, num_layers=1, batch_first=True)\n",
    "        self.fc_layer = nn.Linear(hidden_dim, out_dim)\n",
    "        \n",
    "    def forward(self, seq):\n",
    "        embed = self.embedding_layer(seq)\n",
    "        o, h = self.rnn_layer(embed)\n",
    "        outs = self.fc_layer(h[-1, :, :].squeeze(0))\n",
    "        return outs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(pred, label):\n",
    "    prediction = torch.round(torch.sigmoid(pred))\n",
    "    accs = (prediction == label).sum() / len(label)\n",
    "    return accs \n",
    "\n",
    "def train(model, dataloader, optimizer, criterion):\n",
    "    losses, accs = 0, 0\n",
    "    model.train()\n",
    "    for seq, label in dataloader:\n",
    "        seq = seq.to(device)\n",
    "        label = label.to(device)\n",
    "        preds = model(seq).squeeze()\n",
    "        loss = criterion(preds, label)\n",
    "        acc = accuracy(preds, label)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        losses += loss.item()\n",
    "        accs += acc.item()\n",
    "        \n",
    "    return losses / len(dataloader), accs / len(dataloader )\n",
    "\n",
    "\n",
    "def evaluate(model, dataloader, criterion):\n",
    "    \n",
    "    losses, accs = 0, 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for seq, label in dataloader:\n",
    "            seq = seq.to(device)\n",
    "            label = label.to(device)\n",
    "            preds = model(seq).squeeze()\n",
    "            loss = criterion(preds, label)\n",
    "            acc = accuracy(preds, label)\n",
    "            \n",
    "            losses += loss.item()\n",
    "            accs += acc.item()\n",
    "            \n",
    "    return loss / len(dataloader), accs / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(vocab_to_token) + 1 \n",
    "emb_dim = 128\n",
    "hidden_dim = 32\n",
    "out_dim = 1\n",
    "\n",
    "rnn_model = RNN(input_dim, emb_dim, hidden_dim, out_dim).to(device)\n",
    "\n",
    "optimizer = optim.Adam(rnn_model.parameters())\n",
    "criterion = nn.BCEWithLogitsLoss().to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: [10/100]\n",
      "train_loss: 0.7105\t train_accuracy: 48.51%\n",
      "valid_loss: 0.1412\t valid_accuracy: 48.49%\n",
      "\n",
      "epoch: [20/100]\n",
      "train_loss: 0.7105\t train_accuracy: 48.53%\n",
      "valid_loss: 0.1439\t valid_accuracy: 48.40%\n",
      "\n",
      "epoch: [30/100]\n",
      "train_loss: 0.7105\t train_accuracy: 48.51%\n",
      "valid_loss: 0.1427\t valid_accuracy: 48.44%\n",
      "\n",
      "epoch: [40/100]\n",
      "train_loss: 0.7107\t train_accuracy: 48.46%\n",
      "valid_loss: 0.1435\t valid_accuracy: 48.54%\n",
      "\n",
      "epoch: [50/100]\n",
      "train_loss: 0.7106\t train_accuracy: 48.46%\n",
      "valid_loss: 0.1405\t valid_accuracy: 48.53%\n",
      "\n",
      "epoch: [60/100]\n",
      "train_loss: 0.7105\t train_accuracy: 48.51%\n",
      "valid_loss: 0.1438\t valid_accuracy: 48.42%\n",
      "\n",
      "epoch: [70/100]\n",
      "train_loss: 0.7108\t train_accuracy: 48.41%\n",
      "valid_loss: 0.1423\t valid_accuracy: 48.43%\n",
      "\n",
      "epoch: [80/100]\n",
      "train_loss: 0.7104\t train_accuracy: 48.55%\n",
      "valid_loss: 0.1421\t valid_accuracy: 48.54%\n",
      "\n",
      "epoch: [90/100]\n",
      "train_loss: 0.7105\t train_accuracy: 48.50%\n",
      "valid_loss: 0.1415\t valid_accuracy: 48.49%\n",
      "\n",
      "epoch: [100/100]\n",
      "train_loss: 0.7108\t train_accuracy: 48.46%\n",
      "valid_loss: 0.1438\t valid_accuracy: 48.43%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "best_loss = float('inf')\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    \n",
    "    train_loss, train_acc = train(rnn_model, train_loader, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(rnn_model, valid_loader, criterion)\n",
    "    \n",
    "    if best_loss > valid_loss:\n",
    "        best_loss = valid_loss \n",
    "        torch.save(rnn_model.state_dict(), 'rnn_model.pt')\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(f'epoch: [{epoch}/{num_epochs}]')\n",
    "        print(f'train_loss: {train_loss:.4f}\\t train_accuracy: {train_acc*100:.2f}%')\n",
    "        print(f'valid_loss: {valid_loss:.4f}\\t valid_accuracy: {valid_acc*100:.2f}%\\n')\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('embedding_layer.weight',\n",
       "              tensor([[ 0.7665,  0.9837, -1.0978,  ...,  0.5815,  1.0364, -1.6115],\n",
       "                      [ 0.7764,  0.9626, -0.6196,  ...,  0.8618, -1.6589,  0.6475],\n",
       "                      [-1.3121, -0.2634, -0.1814,  ..., -0.1039, -0.0146, -1.9407],\n",
       "                      ...,\n",
       "                      [-0.0804, -0.6694, -0.5183,  ...,  0.6631, -0.8632, -1.3398],\n",
       "                      [-0.0711, -2.4533, -0.8975,  ..., -0.1902, -0.1618,  0.9095],\n",
       "                      [-1.6899,  1.6587, -1.4952,  ..., -1.1534, -0.9873, -0.3995]],\n",
       "                     device='cuda:0')),\n",
       "             ('rnn_layer.weight_ih_l0',\n",
       "              tensor([[-0.1693,  0.0174, -0.1606,  ...,  0.1183,  0.0540,  0.1672],\n",
       "                      [-0.0548, -0.0934,  0.1050,  ..., -0.0238, -0.0843, -0.1627],\n",
       "                      [-0.0982, -0.1354,  0.0971,  ..., -0.0522, -0.1076, -0.1122],\n",
       "                      ...,\n",
       "                      [-0.0144,  0.0399, -0.0067,  ...,  0.1542,  0.0099,  0.0355],\n",
       "                      [-0.1195, -0.0249,  0.1726,  ..., -0.0515, -0.1533,  0.1486],\n",
       "                      [ 0.0748,  0.1329,  0.1590,  ..., -0.0081,  0.0534, -0.0537]],\n",
       "                     device='cuda:0')),\n",
       "             ('rnn_layer.weight_hh_l0',\n",
       "              tensor([[ 0.0577, -0.1188, -0.1433,  ..., -0.1072,  0.0748, -0.0048],\n",
       "                      [-0.0684, -0.1017,  0.0118,  ...,  0.1141,  0.1575,  0.1451],\n",
       "                      [-0.0562, -0.0515, -0.0456,  ..., -0.0393,  0.0836,  0.0585],\n",
       "                      ...,\n",
       "                      [ 0.1668, -0.0263, -0.1587,  ...,  0.0219, -0.1149,  0.1431],\n",
       "                      [ 0.1392,  0.0205, -0.1019,  ...,  0.0703, -0.0544,  0.1331],\n",
       "                      [-0.0338, -0.0028,  0.1751,  ...,  0.1549,  0.0566,  0.0438]],\n",
       "                     device='cuda:0')),\n",
       "             ('rnn_layer.bias_ih_l0',\n",
       "              tensor([-0.0574, -0.0949, -0.1273,  0.1091,  0.1668,  0.1586, -0.0608,  0.0194,\n",
       "                       0.1159, -0.0864,  0.1230,  0.0816,  0.1340,  0.0604, -0.1000,  0.0966,\n",
       "                       0.0996,  0.0536, -0.1086, -0.1143, -0.1442,  0.0957, -0.0020, -0.1467,\n",
       "                      -0.1354,  0.0119,  0.0842, -0.0051,  0.0488,  0.1009, -0.1112,  0.1578],\n",
       "                     device='cuda:0')),\n",
       "             ('rnn_layer.bias_hh_l0',\n",
       "              tensor([ 0.1171,  0.1231,  0.1639, -0.0316, -0.0269, -0.1474,  0.0392,  0.0678,\n",
       "                       0.0903,  0.1657,  0.0440, -0.0702,  0.0780,  0.0373,  0.1617,  0.0703,\n",
       "                      -0.0826,  0.0916, -0.1322, -0.0009, -0.0959,  0.1147,  0.0871,  0.1569,\n",
       "                       0.1760, -0.0470, -0.1557,  0.0380,  0.0379, -0.1588, -0.0184, -0.0871],\n",
       "                     device='cuda:0')),\n",
       "             ('fc_layer.weight',\n",
       "              tensor([[-0.0350,  0.1462, -0.0438,  0.0865, -0.0362,  0.1719, -0.0957, -0.1254,\n",
       "                        0.0808,  0.1170,  0.1249, -0.0528,  0.1238,  0.0915, -0.0073,  0.0861,\n",
       "                        0.0020, -0.0036, -0.0710,  0.0457, -0.0944,  0.0960, -0.0027, -0.0139,\n",
       "                        0.1697, -0.0387,  0.0926, -0.1111,  0.1622,  0.1052,  0.0712, -0.0601]],\n",
       "                     device='cuda:0')),\n",
       "             ('fc_layer.bias', tensor([-0.0361], device='cuda:0'))])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = os.path.join(os.getcwd(), 'rnn_model.pt')\n",
    "\n",
    "rnn_model = RNN(input_dim, emb_dim, hidden_dim, out_dim).to(device)\n",
    "rnn_model.state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample2feats(sample):\n",
    "    sample = sample.lower()\n",
    "    sample = ''.join([c for c in sample if c not in punctuation])\n",
    "    tokenized = [vocab_to_token.get(token, 0) for token in sample.split()]\n",
    "    tokenized = np.pad(tokenized, (512-len(tokenized), 0), 'constant')\n",
    "    return tokenized\n",
    "    \n",
    "samples = ['So So happy!', 'this movie so terrible', 'This film is horrible', 'This film is very good', 'I loved the movie, every part of it']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer = []\n",
    "for sample in samples:\n",
    "    infer.append(sample2feats(sample))\n",
    "infer = torch.tensor(np.array(infer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5449953079223633\n",
      "0.6242840886116028\n",
      "0.49887457489967346\n",
      "0.5197864174842834\n",
      "0.5529115200042725\n"
     ]
    }
   ],
   "source": [
    "for sample in infer:\n",
    "    sample = sample.to(device).unsqueeze(0)\n",
    "    pred_y = rnn_model(sample)\n",
    "    pred_y = torch.sigmoid(pred_y)\n",
    "    \n",
    "    print(pred_y.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "82ed002fa2d4956f5c6aec99bcefe0f73a9f79882f3c9e2319b14958a5896ac5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
